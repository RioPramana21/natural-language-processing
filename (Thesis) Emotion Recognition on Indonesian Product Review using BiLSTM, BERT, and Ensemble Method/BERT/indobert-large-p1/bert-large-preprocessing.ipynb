{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom transformers import BertTokenizer\nimport torch\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\npd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:58:56.105856Z","iopub.execute_input":"2024-03-26T14:58:56.106226Z","iopub.status.idle":"2024-03-26T14:59:05.726498Z","shell.execute_reply.started":"2024-03-26T14:58:56.106195Z","shell.execute_reply":"2024-03-26T14:59:05.725229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(file_path):\n    \"\"\"Load dataset from a file path.\"\"\"\n    df = pd.read_csv(file_path)\n    columns_to_keep = ['Customer Review', 'Emotion']\n    return df[columns_to_keep]\n\ndef clean_text(df):\n    # Lowercase conversion if using an uncased model\n    df['Customer Review'] = df['Customer Review'].str.lower()\n    \n    # Remove extra whitespaces\n    df['Customer Review'] = df['Customer Review'].str.strip().replace(r'\\s+', ' ', regex=True)\n    return df\n\ndef encode_labels(df):\n    \"\"\"Encode emotion labels.\"\"\"\n    label_encoder = LabelEncoder()\n    df['Emotion'] = label_encoder.fit_transform(df['Emotion'])\n    return df, label_encoder.classes_\n\ndef visualize_tokens_len(df, tokenizer):\n    \"\"\"Visualize the distribution of token lengths in the dataset.\"\"\"\n    token_lens = []\n\n    for txt in df['Customer Review']:\n        tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n        token_lens.append(len(tokens))\n        \n    sns.histplot(token_lens, kde=False)\n    plt.xlim([0, 256])\n    plt.xlabel('Token count')\n    plt.ylabel('Number of reviews')\n    plt.title('Distribution of Review Token Lengths')\n    plt.show()\n\ndef preprocess_data(df, tokenizer):\n    \"\"\"Preprocess data using the provided tokenizer.\"\"\"\n    \n    encoded_data = tokenizer.batch_encode_plus(\n        df['Customer Review'].values, \n        add_special_tokens=True, \n        return_attention_mask=True, \n        padding='max_length', \n        max_length=MAX_LEN,  # Use the global variable\n        return_tensors='pt',\n        truncation=True\n    )\n    \n    input_ids = encoded_data['input_ids']\n    attention_masks = encoded_data['attention_mask']\n    labels = torch.tensor(df['Emotion'].values)\n    \n    # Save the tensors to file\n    torch.save(input_ids, 'input_ids.pt')\n    torch.save(attention_masks, 'attention_masks.pt')\n    torch.save(labels, 'labels.pt')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:59:05.728505Z","iopub.execute_input":"2024-03-26T14:59:05.729039Z","iopub.status.idle":"2024-03-26T14:59:05.74283Z","shell.execute_reply.started":"2024-03-26T14:59:05.729Z","shell.execute_reply":"2024-03-26T14:59:05.741686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = \"https://raw.githubusercontent.com/marceljonathan/natural-language-processing/main/PRDECT-ID%20Dataset.csv\"  # Update this to your dataset's path\noriginal_df = load_data(file_path)\noriginal_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:59:05.744516Z","iopub.execute_input":"2024-03-26T14:59:05.745625Z","iopub.status.idle":"2024-03-26T14:59:06.528109Z","shell.execute_reply.started":"2024-03-26T14:59:05.74559Z","shell.execute_reply":"2024-03-26T14:59:06.526894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = clean_text(original_df)\ndf, label_classes = encode_labels(df)\nprint(label_classes)\n# Optionally, save the mapping of encoded labels to emotions to a file\npd.Series(label_classes).to_csv('label_classes.csv', index = False)\ntokenizer_model = 'indobenchmark/indobert-large-p1'\ntokenizer = BertTokenizer.from_pretrained(tokenizer_model)\n\nvisualize_tokens_len(df, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:59:06.531008Z","iopub.execute_input":"2024-03-26T14:59:06.53137Z","iopub.status.idle":"2024-03-26T14:59:15.203768Z","shell.execute_reply.started":"2024-03-26T14:59:06.53134Z","shell.execute_reply":"2024-03-26T14:59:15.202445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 128 # Based on the distribution","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:59:15.205784Z","iopub.execute_input":"2024-03-26T14:59:15.206221Z","iopub.status.idle":"2024-03-26T14:59:15.211778Z","shell.execute_reply.started":"2024-03-26T14:59:15.206179Z","shell.execute_reply":"2024-03-26T14:59:15.210781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess_data(df, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:59:15.213087Z","iopub.execute_input":"2024-03-26T14:59:15.213384Z","iopub.status.idle":"2024-03-26T14:59:20.855567Z","shell.execute_reply.started":"2024-03-26T14:59:15.213358Z","shell.execute_reply":"2024-03-26T14:59:20.854405Z"},"trusted":true},"execution_count":null,"outputs":[]}]}